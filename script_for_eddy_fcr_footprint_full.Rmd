---
title: "FCR_Process_BD"
author: "Brenda D'Achuna, Alex Hounshell, Adrienne Breef-Pilz, Bibek Kandel"
date: "`r Sys.Date()`"
output: html_document
---

 This script: Following initial data corrections in Eddy Pro (using standard processing) 
 and light data cleaning via EddyPro_CleanUp.R. Note: This script is only a chunk of the full  script 'eddy-flux_processing_2020_2024.Rmd' (located in EDI) to create a non-gap filled flux  data for the purpose of the manuscript.
 
 Original code from Brenda D'Achuna, 21 May 2021
 Modified by Alex Hounshell on 21 May 2021
 Updated by Bibek Kandel on 24 Jan 2025
 
 1. Compile data
 
 2. Read in Met files from Environmental Data Initiative
 
 3. Adjust values and do additional QAQC
 
 4. Use de spike function to remove values
 
 5. Add Met values as needed

 

```{r setup, include=FALSE}

# Download/load libraries
pacman::p_load(tidyverse,lubridate,readr,ggpubr,openair,REddyProc)

# functions we need
source("https://raw.githubusercontent.com/CareyLabVT/Reservoirs/master/Data/DataNotYetUploadedToEDI/EddyFlux_Processing/despike.R")

```


```{r Compile data, include=FALSE}
# Read compiled file: From Eddy Pro using basic processing
# Original file from Brenda on 11 May 2021
# Light data cleaning using EddyPro_CleanUp.R

# Read in the L1 file which is the summary files from the EddyFlux system
dt1 <-read_csv("https://raw.githubusercontent.com/FLARE-forecast/FCRE-data/fcre-eddyflux-data-qaqc/EddyFlux_streaming_L1.csv")

# Check here on EDI an make sure you are using the most up to date file.
# https://portal.edirepository.org/nis/mapbrowse?packageid=edi.1061.2 
# Update the file path if the previous version is out of date 

# read in the data file downloaded from EDI. This is the package from 2020-2023 data. When you update this link, update the date range for the data. 
dt2 <-read_csv("https://pasta.lternet.edu/package/data/eml/edi/1061/4/311d766dd7275d578699380f8996f089") 

# Bind the current and the historical data together
ec <- dt2%>%
 bind_rows(.,dt1)

#FOR USING YEAR-ROUND UPLOADED DATA FROM EDI. This overwrites the bind above. 
ec <- dt2
```

```{r format time, echo=FALSE}
# Format time
# make a datetime column and read in with original timezone
ec$datetime <- paste0(ec$date, " ",ec$time)

# Set timezone as America/New_York because that's what it is in and then convert to EST
  ec$datetime <- force_tz(ymd_hms(ec$datetime), tzone = "America/New_York")

# convert from Eastern/US with daylight savings observed to EST which does not. 
ec$datetime <- with_tz(ec$datetime, tzone = "EST")

# get the late date in the dataframe
last <- tail(ec, n = 1) 


# Set new dataframe with list of dates+times:
# every 30 minutes
# Constrain to study time period: 2020-04-05 (time series start date) to
# last 30 minute period - UPDATE WITH EACH NEW SET OF DATA!
ts <- seq.POSIXt(as.POSIXct("2020-04-05 00:00:00",'%Y-%m-%d %H:%M:%S', tz="EST"), 
                 as.POSIXct(last$datetime,'%Y-%m-%d %H:%M:%S', tz="EST"), by = "30 min")
ts2 <- data.frame(datetime = ts)

# Join Eddy Flux data with list of dates+time
ec2 <- merge(ts2, ec, by = 'datetime', all.x=T)


# Make sure time stamps are okay!
ec2 %>% group_by(year = year(datetime), month = factor(month.abb[month(datetime)], levels = c("Apr", "May", "Jun",
                                                                                                 "Jul", "Aug", "Sep", "Oct", 'Nov', 
                                                                                                 'Dec', 'Jan', 'Feb', 'Mar')), 
                    hour = hour(datetime)) %>% 
  summarise(air_temperature = mean(air_temperature_k, na.rm = TRUE)) %>% 
  ggplot(aes(hour, air_temperature, col = factor(year))) + geom_point() + 
  facet_wrap(~month) + theme_bw() + ylab('Air Temp') + xlab("") +
  scale_color_brewer(palette = "Dark2")
```

```{r Percent of NAs, echo=FALSE}
#################################################################
# Count how many initial NAs are in CO2 and CH4 data
# Without any data processing!
#################################################################
sta<-ec2 %>% select(datetime, co2_flux_umolm2s, ch4_flux_umolm2s) %>% 
  summarise(co2_available = 100-sum(is.na(co2_flux_umolm2s))/n()*100,
            ch4_available = 100-sum(is.na(ch4_flux_umolm2s))/n()*100)
# 72.2% data for CO2; 74.8% data for CH4

# Check data availability by month
ec2 %>% group_by(year(datetime), month(datetime)) %>% select(datetime, co2_flux_umolm2s, ch4_flux_umolm2s) %>% 
  summarise(co2_available = 100-sum(is.na(co2_flux_umolm2s))/n()*100,
            ch4_available = 100-sum(is.na(ch4_flux_umolm2s))/n()*100)
#################################################################
```

```{r Inital Flux plots, echo=FALSE}

ec2%>%
  select(datetime, co2_flux_umolm2s, ch4_flux_umolm2s)%>%
  tidyr::pivot_longer(cols=c(co2_flux_umolm2s, ch4_flux_umolm2s), # make the wide data frame into a long one so each observation has a depth
                 names_to='variable',
                 values_to='observation')%>%
  ggplot(., aes(x=datetime, y=observation))+
  geom_point()+
  facet_wrap(~variable, scales="free_y", ncol=1)+
   ggtitle("Inital Fluxes Prime 0")+
  theme_bw()+
   theme(plot.title = element_text(hjust = 0.5))
  
ggsave("FCR_InitalFluxes.jpg", width=11, height=7, units="in")


```


Count how many initial NAs are in CO2 and CH4 data. Without any data processing!
`r round(sta$co2_available, digits=1)`% data for Co2;  
`r round(sta$ch4_available, digits=1)`% data for Ch4

```{r Read in Met Data, include=FALSE}
# Reading in data from the Met Station for gap-filling purposes
# Load data Meteorological data from EDI
#Note: This is a huge file and takes about 15-20 minutes to download. PATIENCE NEEDED!!!

## Double check that you have the most up to date 


# Read in Met file from EDI. Data from 2015-2024. Update the date range when you update the link. 
met_all <- read_csv("https://pasta.lternet.edu/package/data/eml/edi/389/9/62647ecf8525cdfc069b8aaee14c0478",
                    col_select=c("DateTime","PAR_umolm2s_Average","PAR_Total_mmol_m2","BP_Average_kPa",
                                 "AirTemp_C_Average","RH_percent","Rain_Total_mm",
                                 "ShortwaveRadiationUp_Average_W_m2", "ShortwaveRadiationDown_Average_W_m2",
                                  "InfraredRadiationUp_Average_W_m2","InfraredRadiationDown_Average_W_m2",
                                  "Albedo_Average_W_m2","WindSpeed_Average_m_s","WindDir_degrees"))%>%
  mutate(DateTime = force_tz(DateTime, tzone="EST"))%>% 
  # Start timeseries on the 00:15:00 to facilitate 30-min averages
  filter(DateTime >= ymd_hms("2020-04-04 00:15:00"))

# Bind files together if need to use current file

met_curr <- read_csv("https://raw.githubusercontent.com/FLARE-forecast/FCRE-data/fcre-metstation-data-qaqc/FCRmet_L1.csv",
                   col_select=c("DateTime","PAR_umolm2s_Average","PAR_Total_mmol_m2","BP_Average_kPa",
                                 "AirTemp_C_Average","RH_percent","Rain_Total_mm",
                                 "ShortwaveRadiationUp_Average_W_m2", "ShortwaveRadiationDown_Average_W_m2",
                                  "InfraredRadiationUp_Average_W_m2","InfraredRadiationDown_Average_W_m2",
                                  "Albedo_Average_W_m2","WindSpeed_Average_m_s","WindDir_degrees"))%>%
  mutate(DateTime = force_tz(DateTime, tzone="EST"))

 met_all <- dplyr::bind_rows(met_curr, met_all) # bind everything together
  
  
# Start timeseries on the 00:15:00 to facilitate 30-min averages

# Select data every 30 minutes from Jan 2020 to end of met data
met_all$Breaks <- cut(met_all$DateTime,breaks = "30 mins",right=FALSE)
met_all$Breaks <- ymd_hms(as.character(met_all$Breaks))

# Average met data to the 30 min mark (excluding Total Rain and Total PAR)
met_30 <- met_all %>% 
 select(-c(Rain_Total_mm,PAR_Total_mmol_m2))%>%
  group_by(Breaks) %>% 
  summarise_all(mean,na.rm=TRUE)

```

```{r Adjust Met values for EddyFlux timing, include=FALSE}
# Sum met data to the 30 min mark (for Total Rain and Total PAR)
met_30_rain <- met_all %>% 
  select(Rain_Total_mm,PAR_Total_mmol_m2,Breaks) %>% 
  group_by(Breaks) %>% 
  summarise_all(sum,na.rm=TRUE)

# Combine averaged and summed data together
met_30_2 <- cbind.data.frame(met_30,met_30_rain)

# Adjust datetime to 30 minute intervals, select relevant parameters, and rename
# following Brenda's conventions
met_30_2 <- met_30_2 %>% 
  select(-Breaks) %>% 
  mutate(DateTime_Adj = DateTime + 30) %>% 
  select(-DateTime) %>% 
  rename(datetime = DateTime_Adj, AirTC_Avg = AirTemp_C_Average, RH = RH_percent, Pressure = BP_Average_kPa, 
         Rain_sum = Rain_Total_mm, WS_ms_Avg = WindSpeed_Average_m_s, WindDir = WindDir_degrees,SW_in = ShortwaveRadiationUp_Average_W_m2,
         SW_out = ShortwaveRadiationDown_Average_W_m2,LW_in = InfraredRadiationUp_Average_W_m2,LW_out = InfraredRadiationDown_Average_W_m2,
         PAR_Tot_Tot = PAR_Total_mmol_m2,albedo = Albedo_Average_W_m2)

# Join with 30 minute time series
met2 <- left_join(ts2, met_30_2, by = 'datetime')
```

```{r Compare wind speeds from EC and Met}
# Compare wind speeds from EC and Met

ggplot()+
  geom_point(aes(x=ec2$wind_speed_ms, y=met2$WS_ms_Avg))+
  theme_classic(base_size = 15)
  

# Calculate percent of missing wind data
# 10.4% missing
miss_ws<-ec2 %>% select(datetime, wind_speed_ms) %>% 
  summarise(wnd_na = sum(is.na(wind_speed_ms))/n()*100)
```

We are missing `r round(miss_ws$wnd_na, digits=1)` % of the windspeed observations

```{r Use linear model to convert from Met to EC for missing time point}
# Use linear model to convert from Met to EC for missing time point
linearMod <- lm(ec2$wind_speed_ms ~ met2$WS_ms_Avg)
summary(linearMod)
cor(ec2[[49]],met2[[11]],use = "complete.obs",method=c("pearson"))

# UPDATE EVERY YEAR WITH NEW RELATIONSHIP
# For data period: EC = Met*0.541570+0.154306

# Check conversion - UPDATE EVERY YEAR WITH NEW RELATIONSHIP
plot(ec2$datetime, ec2$wind_speed_ms)
points(ec2$datetime, met2$WS_ms_Avg*(summary(linearMod)$coefficients[2, 1])+(summary(linearMod)$coefficients[1, 1]), col = 'red')
```

The new relationship between the wind speed on the Metstation and the EddyFlux is 

EC= Met* 
`r summary(linearMod)$coefficients[2, 1]` + 
`r summary(linearMod)$coefficients[1, 1]`

```{r QC when wind in wrong direction}
###########################################
# Use converted wind speed from the Met data to fill in time points with missing
# data (EC)
# UPDATE EVERY YEAR WITH NEW RELATIONSHIP
ec2$wind_speed_ms <- ifelse(is.na(ec2$wind_speed_ms),
                         met2$WS_ms_Avg*(summary(linearMod)$coefficients[2, 1])+
                           (summary(linearMod)$coefficients[1, 1]), ec2$wind_speed_ms)

ec2$wind_dir <- ifelse(is.na(ec2$wind_dir),
                       met2$WindDir, ec2$wind_dir)

# Visualize wind directions that are IN FRONT of the catwalk
ec2 %>% filter(wind_dir >= 250 | wind_dir <= 80) %>% 
  ggplot(aes(wind_dir, wind_speed_ms)) + 
  geom_point() +
  scale_x_continuous(limits = c(0, 360),
                     breaks = seq(0, 360, 45)) +
  coord_polar() + theme_bw() + xlab('Wind direction') + ylab('Wind speed')

# Filter out wind directions that are BEHIND the catwalk
# I.e., only keep data that is IN FRONT of the catwalk for both EC and Met data
ec_filt <- ec2 %>% dplyr::filter(wind_dir < 80 | wind_dir > 250)
ec_filt <- left_join(ts2, ec_filt)

met3 <- met2 %>% dplyr::filter(WindDir < 80 | WindDir > 250)
met4 <- left_join(ts2, met3)

################################################################
# count NA after filtering for wind direction BEHIND catwalk
ec_filt %>% select(datetime, co2_flux_umolm2s, ch4_flux_umolm2s) %>% 
  summarise(co2_available = 100- sum(is.na(co2_flux_umolm2s))/n()*100,
            ch4_available = 100-sum(is.na(ch4_flux_umolm2s))/n()*100)
# Now have 50.34% CO2 data and 53.35% CH4 data

# Count number of timepoints that have data
ec_filt %>% select(datetime, co2_flux_umolm2s, ch4_flux_umolm2s) %>% 
  summarise(co2_available = n() - sum(is.na(co2_flux_umolm2s)),
            ch4_available = n() -sum(is.na(ch4_flux_umolm2s)))
################################################################
```

```{r QC on CO2 fluxes}
# Remove large CO2 values
# Visualize data that is above/below abs(100)
plot(ec_filt$datetime, ec_filt$co2_flux_umolm2s)+
abline(h=100, col="red") +
abline(h=-100, col="red")

# Remove values that are greater than abs(100)
# NOTE: Updated from Brenda's code to use abs(100); instead of -70 to 100 filtering
# Waldo et al. 2021 used: values greater than abs(15000)
ec_filt$co2_flux_umolm2s <- ifelse(ec_filt$co2_flux_umolm2s > 100 | ec_filt$co2_flux_umolm2s < -100, NA, ec_filt$co2_flux_umolm2s)

# Remove CO2 data if QC >= 2 (aka: data that has been flagged by Eddy Pro)
ec_filt$co2_flux_umolm2s <- ifelse(ec_filt$qc_co2_flux >= 2, NA, ec_filt$co2_flux_umolm2s)

# Additionally remove CO2 data when H and LE > 2 (following CH4 filtering)
ec_filt$co2_flux_umolm2s <- ifelse(ec_filt$qc_co2_flux==1 & ec_filt$qc_LE>=2, NA, ec_filt$co2_flux_umolm2s)
ec_filt$co2_flux_umolm2s <- ifelse(ec_filt$qc_co2_flux==1 & ec_filt$qc_H>=2, NA, ec_filt$co2_flux_umolm2s)
```

```{r QC on Ch4 fluxes}
# Remove large CH4 values
# Visualize data that is above/below abs(0.25)
plot(ec_filt$datetime, ec_filt$ch4_flux_umolm2s)+
abline(h=0.25, col='red')+
abline(h=-0.25, col='red')

# Remove values that are greater than abs(0.25)
# NOTE: Updated from Brenda's code to use abs(0.25)
# Waldo et al. 2021 used: values greater than abs(500)
ec_filt$ch4_flux_umolm2s <- ifelse(ec_filt$ch4_flux_umolm2s >= 0.25 | ec_filt$ch4_flux_umolm2s <= -0.25, NA, ec_filt$ch4_flux_umolm2s)

# Remove ch4 values when signal strength < 20
ec_filt$ch4_flux_umolm2s <- ifelse(ec_filt$rssi_77_mean < 20, NA, ec_filt$ch4_flux_umolm2s)

# Remove CH4 data if QC >= 2
ec_filt$ch4_flux_umolm2s <- ifelse(ec_filt$qc_ch4_flux >=2, NA, ec_filt$ch4_flux_umolm2s)

# Additionally, remove CH4 when other parameters are QA/QC'd 
# Following Waldo et al. 2021: Remove additional ch4 flux data 
# (aka: anytime ch4_qc flag = 1 & another qc_flag =2, remove)
ec_filt$ch4_flux_umolm2s <- ifelse(ec_filt$qc_ch4_flux==1 & ec_filt$qc_co2_flux>=2, NA, ec_filt$ch4_flux_umolm2s)
ec_filt$ch4_flux_umolm2s <- ifelse(ec_filt$qc_ch4_flux==1 & ec_filt$qc_LE>=2, NA, ec_filt$ch4_flux_umolm2s)
ec_filt$ch4_flux_umolm2s <- ifelse(ec_filt$qc_ch4_flux==1 & ec_filt$qc_H>=2, NA, ec_filt$ch4_flux_umolm2s)
```

```{r Check QC for H and LE}
# Removing qc >= 2 for H and LE
ec_filt$H_wm2 <- ifelse(ec_filt$qc_H >= 2, NA, ec_filt$H_wm2)
ec_filt$LE_wm2 <- ifelse(ec_filt$qc_LE >= 2, NA, ec_filt$LE_wm2)

# Remove high H values: greater than abs(200)
# NOTE: Updated to have same upper and lower magnitude bound
# Waldo et al. 2021 used abs of 200 for H
plot(ec_filt$datetime, ec_filt$H_wm2)+
abline(h=200, col='red')+
abline(h=-200, col='red')

ec_filt$H_wm2 <- ifelse(ec_filt$H_wm2 >= 200 | ec_filt$H_wm2 <= -200, NA, ec_filt$H_wm2)

# Remove high LE values: greater than abs(500)
# NOTE: Updated to have same upper and lower magnitude bounds
# Waldo et al. 2021 used abs of 1000 for LE
plot(ec_filt$datetime,ec_filt$LE_wm2)+
abline(h=500, col='red')+
abline(h=-500, col='red')

ec_filt$LE_wm2 <- ifelse(ec_filt$LE_wm2 >= 500 | ec_filt$LE_wm2 <= -500, NA, ec_filt$LE_wm2)

# Plotting co2 and ch4 to see if we can filter implausible values
plot(ec_filt$co2_flux_umolm2s, type = 'o')
plot(ec_filt$ch4_flux_umolm2s, type = 'o')
```

```{r Take out CH4 flux when rain}
################################################################
# count NA after filtering for bad fluxes
ec_filt %>% select(datetime, co2_flux_umolm2s, ch4_flux_umolm2s) %>% 
  summarise(co2_available = 100- sum(is.na(co2_flux_umolm2s))/n()*100,
            ch4_available = 100-sum(is.na(ch4_flux_umolm2s))/n()*100)
# Now have 32.62% CO2 data and 30.31% CH4 data

# Count number of timepoints that have data
ec_filt %>% select(datetime, co2_flux_umolm2s, ch4_flux_umolm2s) %>% 
  summarise(co2_available = n() - sum(is.na(co2_flux_umolm2s)),
            ch4_available = n() -sum(is.na(ch4_flux_umolm2s)))
################################################################

# Remove CH4 when it rains
ec_filt$precip <- met2$Rain_sum
ec_filt$ch4_flux_umolm2s <- ifelse(ec_filt$precip > 0, NA, ec_filt$ch4_flux_umolm2s)

# Remove CH4 data when thermocouple was not working (apr 05 - apr 25) # ABP find for 2023
ec_filt$ch4_flux_umolm2s <- ifelse(ec_filt$datetime >= '2021-04-05' & ec_filt$datetime <= '2021-04-25', 
                           NA, ec_filt$ch4_flux_umolm2s)

# Merge with timeseries
eddy_fcr <- left_join(ts2, ec_filt, by = 'datetime')

```

```{r Count data}
#######################################################################
# counting data again after filtering by:
# wind direction, qc, rain, unreasonable values, signal strength
eddy_fcr %>% select(datetime, co2_flux_umolm2s, ch4_flux_umolm2s) %>% 
  summarise(co2_available = 100-sum(is.na(co2_flux_umolm2s))/n()*100,
            ch4_available = 100-sum(is.na(ch4_flux_umolm2s))/n()*100)
# 32.62% CO2 data; 29.86% CH4 data

# Number of timepoints available
eddy_fcr %>% select(datetime, co2_flux_umolm2s, ch4_flux_umolm2s) %>% 
  summarise(co2_available = n() - sum(is.na(co2_flux_umolm2s)),
            ch4_available = n() -sum(is.na(ch4_flux_umolm2s)))

# Data availability by month
eddy_fcr %>% group_by(year(datetime), month(datetime)) %>% select(datetime, co2_flux_umolm2s, ch4_flux_umolm2s) %>% 
  summarise(co2_available = 100-sum(is.na(co2_flux_umolm2s))/n()*100,
            ch4_available = 100-sum(is.na(ch4_flux_umolm2s))/n()*100)
```

```{r Use Despike function}
########################################################################
# Despike data using despike.R function

# Despike NEE (CO2 flux)


# Calculate low, medium, and high data flags
flag <- spike_flag(eddy_fcr$co2_flux_umolm2s,z = 7)
NEE_low <- ifelse(flag == 1, NA, eddy_fcr$co2_flux_umolm2s)
flag <- spike_flag(eddy_fcr$co2_flux_umolm2s,z = 5.5)
NEE_medium <- ifelse(flag == 1, NA, eddy_fcr$co2_flux_umolm2s)
flag <- spike_flag(eddy_fcr$co2_flux_umolm2s,z = 4)
NEE_high <- ifelse(flag == 1, NA, eddy_fcr$co2_flux_umolm2s)

# Plot flagged data:
plot(eddy_fcr$datetime,eddy_fcr$co2_flux_umolm2s,xlab = "Date", ylab = "NEE (umol m-2s-1)", col = "gray70")+
points(eddy_fcr$datetime,NEE_low,col = "gray10")+
points(eddy_fcr$datetime,NEE_medium,col = "blue")+
points(eddy_fcr$datetime,NEE_high,col = "red")+
abline(h=0)

# Combine all flagged data
eddy_fcr$NEE.low <- NEE_low
eddy_fcr$NEE.med <- NEE_medium
eddy_fcr$NEE.high <- NEE_high

#Despike CH4 flux
flag <- spike_flag(eddy_fcr$ch4_flux_umolm2s,z = 7)
CH4_low <- ifelse(flag == 1, NA, eddy_fcr$ch4_flux_umolm2s)
flag <- spike_flag(eddy_fcr$ch4_flux_umolm2s,z = 5.5)
CH4_medium <- ifelse(flag == 1, NA, eddy_fcr$ch4_flux_umolm2s)
flag <- spike_flag(eddy_fcr$ch4_flux_umolm2s,z = 4)
CH4_high <- ifelse(flag == 1, NA, eddy_fcr$ch4_flux_umolm2s)

# Plot flagged data:
plot(eddy_fcr$datetime,eddy_fcr$ch4_flux_umolm2s,xlab = "Date", ylab = "CH4 (umol m-2s-1)", col = "gray70")+
points(eddy_fcr$datetime,CH4_low,col = "gray10")+
points(eddy_fcr$datetime,CH4_medium,col = "blue")+
points(eddy_fcr$datetime,CH4_high,col = "red")+
abline(h=0)

# Combine all flagged data
eddy_fcr$ch4.low <- CH4_low
eddy_fcr$ch4.med <- CH4_medium
eddy_fcr$ch4.high <- CH4_high
```

```{r QAQC using Met data}
##########################################################################
# Convert EC temperature to celsius
eddy_fcr$air_temp_celsius <- eddy_fcr$air_temperature_k - 273.15
eddy_fcr$sonic_temp_celsius <- eddy_fcr$sonic_temperature_k - 273.15

# Plot temperature
ggplot(eddy_fcr,mapping=aes(x=datetime,y=air_temp_celsius))+
  geom_point()+
  theme_classic(base_size=15)

ggplot(eddy_fcr,mapping=aes(x=datetime,y=sonic_temp_celsius))+
  geom_point()+
  theme_classic(base_size=15)

# Remove any values over 40 

eddy_fcr$air_temp_celsius <- ifelse(eddy_fcr$air_temp_celsius>40, NA, 
                                    eddy_fcr$air_temp_celsius)

# Remove bad air temps on 10 Feb to 14 Feb
eddy_fcr$air_temp_celsius <- ifelse(eddy_fcr$datetime >= '2021-02-10' & eddy_fcr$datetime <='2021-02-14', NA, 
                                    eddy_fcr$air_temp_celsius)
eddy_fcr$sonic_temp_celsius <- ifelse(eddy_fcr$datetime >= '2021-02-10' & eddy_fcr$datetime <='2021-02-14', NA, 
                                      eddy_fcr$sonic_temp_celsius)

# Remove high temperatures on 11 November 2020
eddy_fcr$air_temp_celsius <- ifelse(eddy_fcr$datetime >= '2020-11-11' & eddy_fcr$datetime <'2020-11-12', NA, 
                                    eddy_fcr$air_temp_celsius)

eddy_fcr$sonic_temp_celsius <- ifelse(eddy_fcr$datetime >= '2020-11-11' & eddy_fcr$datetime <'2020-11-12', NA, 
                                    eddy_fcr$sonic_temp_celsius)
```

```{r Replacing Eddy Flux air temp with Met air temp}
# Replacing Eddy Flux air temp with Met air temp
# Check correlations between EC temp and Met Temp
ggplot()+
  geom_point(aes(x=eddy_fcr$air_temp_celsius,y=met2$AirTC_Avg))+
  theme_classic(base_size = 15)

# Calculate percent of missing air temp data
# 37.57% missing
eddy_fcr %>% select(datetime, air_temp_celsius) %>% 
  summarise(temp_na = sum(is.na(air_temp_celsius))/n()*100)

# Use linear model to estimate EC temp from Met temp
linearMod_Air <- lm(eddy_fcr$air_temp_celsius ~ met2$AirTC_Avg)
summary(linearMod_Air)
cor(eddy_fcr[[88]],met2[[4]],use = "complete.obs",method=c("pearson"))
# EC = Met*0.9753170-0.9595196
# UPDATE RELATIONSHIP EACH YEAR!!

eddy_fcr$air_temp_celsius <- ifelse(is.na(eddy_fcr$air_temp_celsius),
                                    met2$AirTC_Avg*(summary(linearMod_Air)$coefficients[2, 1])+
                           (summary(linearMod_Air)$coefficients[1, 1]), eddy_fcr$air_temp_celsius)

# Check Air Temp
ggplot(eddy_fcr,mapping=aes(x=datetime,y=air_temp_celsius))+
  geom_point()+
  theme_classic(base_size=15)

# Check correlations between EC temp (sonic) and Met Temp
ggplot()+
  geom_point(aes(x=eddy_fcr$sonic_temp_celsius,y=met2$AirTC_Avg))+
  theme_classic(base_size = 15)

# Calculate percent of missing sonic temp data
# 37.57% missing
eddy_fcr %>% select(datetime, sonic_temp_celsius) %>% 
  summarise(temp_na = sum(is.na(sonic_temp_celsius))/n()*100)

# Use linear model to estimate EC temp and Met temp
linearMod_Air2 <- lm(eddy_fcr$sonic_temp_celsius ~ met2$AirTC_Avg)
summary(linearMod_Air2)
cor(eddy_fcr[[89]],met2[[4]],use = "complete.obs",method=c("pearson"))
# EC = Met*1.0395534-0.7605165
# UPDATE RELATIONSHIP EACH YEAR!!

eddy_fcr$sonic_temp_celsius <- ifelse(is.na(eddy_fcr$sonic_temp_celsius),
                                      eddy_fcr$air_temp_celsius*(summary(linearMod_Air2)$coefficients[2, 1])+
                           (summary(linearMod_Air2)$coefficients[1, 1]), eddy_fcr$sonic_temp_celsius)

# Check sonic temp
ggplot(eddy_fcr,mapping=aes(x=datetime,y=sonic_temp_celsius))+
  geom_point()+
  theme_classic(base_size=15)

# Replacing Eddy Flux RH with Met RH
# Check correlations between EC and Met RH
ggplot()+
  geom_point(aes(x=eddy_fcr$RH,y=met2$RH))+
  theme_classic(base_size = 15)

# Calculate percent of missing RH
# 47.27% missing
eddy_fcr %>% select(datetime, RH) %>% 
  summarise(RH_na = sum(is.na(RH))/n()*100)

# Use linear model to estimate EC RH from Met RH
linearMod_RH <- lm(eddy_fcr$RH ~ met2$RH)
summary(linearMod_RH)
cor(eddy_fcr[[46]],met2[[5]],use = "complete.obs",method=c("pearson"))
# EC = Met*0.838366 + 9.891706
# UPDATE EACH YEAR!!

eddy_fcr$RH <- ifelse(is.na(eddy_fcr$RH),
                      met2$RH*(summary(linearMod_RH)$coefficients[2, 1])+
                           (summary(linearMod_RH)$coefficients[1, 1]), eddy_fcr$RH)

# Add Met data to gapfill fluxes
eddy_fcr$SW_in <- met2$SW_in
eddy_fcr$SW_out <- met2$SW_out
eddy_fcr$par_tot <- met2$PAR_Tot_Tot
eddy_fcr$air_pressure <- met2$Pressure
eddy_fcr$LW_in <- met2$LW_in
eddy_fcr$LW_out <- met2$LW_out
eddy_fcr$albedo <- met2$albedo

```

```{r Look at LW out and Net Radiation}
# Calculate vapor pressure deficit from RH and Air Temp using Met data
eddy_fcr$VPD <- ifelse(is.na(eddy_fcr$VPD), 
                       fCalcVPDfromRHandTair(rH = eddy_fcr$RH, Tair = eddy_fcr$air_temp_celsius)*100, 
                       eddy_fcr$VPD)

# Remove funky PAR_Tot values
eddy_fcr$par_tot <- ifelse(eddy_fcr$datetime >='2020-07-03' & eddy_fcr$datetime <= '2020-07-22', NA, eddy_fcr$par_tot)

# Replace wind_direction in EC data with Met data if missing
eddy_fcr$wind_dir <- ifelse(is.na(eddy_fcr$wind_dir), met4$WindDir, eddy_fcr$wind_dir)

# QA/QC'ing LW_out data
eddy_fcr$LW_out <- ifelse(eddy_fcr$LW_out <= 360, NA, eddy_fcr$LW_out)
eddy_fcr$LW_out <- ifelse(eddy_fcr$datetime >= '2020-06-22' & eddy_fcr$datetime <= '2020-07-13' & eddy_fcr$LW_out <= 420, NA, eddy_fcr$LW_out)

# Calculating Net Radiation
eddy_fcr$Rn <- eddy_fcr$SW_in - eddy_fcr$SW_out + eddy_fcr$LW_in - eddy_fcr$LW_out

plot(eddy_fcr$Rn, type = 'o')

plot(eddy_fcr$SW_in)

plot(eddy_fcr$VPD/1000)  # in kpa
```

```{r Filter out all the values (x_peak) that are out of the reservoir}

###############################################################################
# Filter out all the values (x_peak) that are out of the reservoir
eddy_fcr$footprint_flag <- ifelse(eddy_fcr$wind_dir >= 15 & eddy_fcr$wind_dir <= 90 & eddy_fcr$x_peak_m >= 40, 1, 
                                  ifelse(eddy_fcr$wind_dir < 15 & eddy_fcr$wind_dir > 327 & eddy_fcr$x_peak_m > 120, 1,
                                         ifelse(eddy_fcr$wind_dir < 302 & eddy_fcr$wind_dir >= 250 & eddy_fcr$x_peak_m > 50, 1, 0)))

# Remove flagged data
eddy_fcr_footprint <- eddy_fcr %>% filter(footprint_flag == 0)

# Visualize wind directions that were kept
eddy_fcr_footprint %>% ggplot(aes(wind_dir, x_peak_m)) + 
  geom_hline(yintercept = 40, col = 'goldenrod2', lwd = 2) +
  geom_hline(yintercept = 50, col = 'green', lwd = 1.4) +
  geom_hline(yintercept = 100, col = 'blue', lwd = 1.4) +
  geom_hline(yintercept = 120, col = 'gray2', lwd = 1.4) +
  geom_hline(yintercept = 150, col = 'red',lwd = 1.4) +
  geom_point() +
  scale_x_continuous(limits = c(0, 360),
                     breaks = seq(0, 360, 45)) +
  theme_bw() + 
  coord_polar()

# merge with timeseries
eddy_fcr_footprint_full <- left_join(ts2, eddy_fcr_footprint)

write.csv(eddy_fcr_footprint_full, "Eddy_fcr_footprint_full.csv")

```
